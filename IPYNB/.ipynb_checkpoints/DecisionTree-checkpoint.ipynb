{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-adoption",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import  StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#print tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wine.csv\", delimiter=\";\")\n",
    "del df['ash']\n",
    "display(df)\n",
    "print(f\"the column where at least a column is null are: {sum(df.isnull().sum())}\")\n",
    "print(f\"the shape of the dataset is the following: {df.shape}\")\n",
    "count = df.isnull().sum()\n",
    "print(\"\\nMissing values per column\")\n",
    "print(count.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != \"class\"]\n",
    "y = df[\"class\"]\n",
    "classes = np.unique(y)\n",
    "for c in classes: \n",
    "    total = len(y[y==c])\n",
    "    ratio = (total / float(len(y))) * 100\n",
    "    print(\"Class %s : %d (%.3f%%)\" % (str(c), total, ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'criterion':('gini','entropy'), \n",
    "'min_samples_split':[2,3,4,5,6,7,8],\n",
    "'max_depth':[1,2,3,4,5,6,10,15,20], \n",
    "'class_weight':('balanced', None)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    grid_params,\n",
    ")\n",
    "\n",
    "gs.fit(X,y)\n",
    "model = gs.best_estimator_\n",
    "\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5)\n",
    "acc = []\n",
    "prec =[]\n",
    "rec = []\n",
    "f1 = []\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, y), 1):  \n",
    "    y_train = y[train_index]  \n",
    "    X_train = X.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y[test_index]  \n",
    "    model.fit(X_train, y_train )  \n",
    "    y_pred = model.predict(X_test)\n",
    "   \n",
    "    acc.append(model.score(X_test, y_test))\n",
    "    prec.append(precision_score(y_test, y_pred,average=\"weighted\",labels=np.unique(y_pred)))\n",
    "    rec.append(recall_score(y_test, y_pred,average=\"weighted\",labels=np.unique(y_pred)))\n",
    "    f1.append(f1_score(y_test, y_pred,average=\"weighted\",labels=np.unique(y_pred)))\n",
    "    \n",
    "print(\"Average scores for 5 fold CV - Without SMOTE\")\n",
    "print(\"Accuracy: \" + str(np.mean(acc).round(3)))\n",
    "print(\"Weighted Precision: \" + str(np.mean(prec).round(3)))\n",
    "print(\"Weighted Recall:    \" + str(np.mean(rec).round(3)))\n",
    "print(\"Weighted F1-Score:  \" + str(np.mean(f1).round(3)))\n",
    "\n",
    "dot_data=StringIO()\n",
    "export_graphviz(model, out_file=dot_data, filled=True, rounded=True, special_characters = True, feature_names =X_train.columns.values.tolist())\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_png(\"wineDTC.png\")\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5)\n",
    "acc = []\n",
    "prec =[]\n",
    "rec = []\n",
    "f1 = []\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, y), 1):  \n",
    "    y_train = y[train_index]  \n",
    "    X_train = X.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y[test_index]  \n",
    "    \n",
    "    sm = SMOTE()\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n",
    "  \n",
    "    model.fit(X_train_oversampled, y_train_oversampled )  \n",
    "    y_pred = model.predict(X_test)\n",
    "   \n",
    "    acc.append(model.score(X_test, y_test))\n",
    "    prec.append(precision_score(y_test, y_pred,average=\"weighted\",labels=np.unique(y_pred)))\n",
    "    rec.append(recall_score(y_test, y_pred,average=\"weighted\",labels=np.unique(y_pred)))\n",
    "    f1.append(f1_score(y_test, y_pred,average=\"weighted\",labels=np.unique(y_pred)))\n",
    "    \n",
    "print(\"Average scores for 5 fold CV - With SMOTE\")\n",
    "print(\"Accuracy: \" + str(np.mean(acc).round(3)))\n",
    "print(\"Weighted Precision: \" + str(np.mean(prec).round(3)))\n",
    "print(\"Weighted Recall:    \" + str(np.mean(rec).round(3)))\n",
    "print(\"Weighted F1-Score:  \" + str(np.mean(f1).round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3389ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
